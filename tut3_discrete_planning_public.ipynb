{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsr2SzeLQDgS"
      },
      "source": [
        "# Dependencies\n",
        "\n",
        "**IMPORTANT!**\n",
        "\n",
        "To install necessary dependencies to the Google Colab VM this notebook runs in, please **run all cells in this section before doing anything else**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU9CLhoo1qHW"
      },
      "outputs": [],
      "source": [
        "# download necessary libraries\n",
        "!wget http://downloads.sourceforge.net/project/ltl3ba/ltl3ba/1.1/ltl3ba-1.1.3.tar.gz\n",
        "!wget https://downloads.sourceforge.net/project/buddy/buddy/BuDDy%202.4/buddy-2.4.tar.gz\n",
        "!wget https://netlib.org/voronoi/triangle.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jizDg5zk_7ki"
      },
      "outputs": [],
      "source": [
        "# build buddy library\n",
        "!tar xzf buddy-2.4.tar.gz\n",
        "%cd buddy-2.4\n",
        "!./configure\n",
        "!make\n",
        "!make install\n",
        "%cd ..\n",
        "\n",
        "import os \n",
        "os.environ['LD_LIBRARY_PATH']+='/content/buddy-2.4/src/.libs/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J75Ug5Bv9R2J"
      },
      "outputs": [],
      "source": [
        "# unpack ltl3ba\n",
        "!tar xzf ltl3ba-1.1.3.tar.gz\n",
        "\n",
        "# build it\n",
        "%cd ltl3ba-1.1.3/\n",
        "!sed -i '36s#.*#BUDDY_INCLUDE=/content/buddy-2.4/src/#' Makefile\n",
        "!sed -i '38s#.*#BUDDY_LIB=/content/buddy-2.4/src/.libs/#' Makefile\n",
        "!make\n",
        "%cd ..\n",
        "\n",
        "# set the dynamic library path\n",
        "import os \n",
        "os.environ['LD_LIBRARY_PATH']='/content/buddy-2.4/src/.libs/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5FjUJcl38JR"
      },
      "outputs": [],
      "source": [
        "# unpack triangle\n",
        "!mkdir triangle\n",
        "!unzip \"/content/triangle.zip\" -d \"/content/triangle\"\n",
        "\n",
        "# build it\n",
        "%cd triangle/\n",
        "!make\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1tH8w74wqTk"
      },
      "source": [
        "# Tutorial 3: Discrete Planning\n",
        "\n",
        "This tutorial focusses on exploring basic concepts of high-level task planning via Linear Temporal Logic (LTL) specifications on discrete models of the environment.\n",
        "\n",
        "Throughout the tutorial, we will be using the example of an autonomous system navigating through a bounded workspace, shown in a top-down perspective. In this 2D representation of the workspace, we define static obstacles or abstract regions of interest through polygons. \n",
        "\n",
        "We assume the autonomous system is able to move freely in this workspace. Specifically, this tutorial does not reason over the dynamics of that autonomous system. Imagine the scale of this environment to be large enough for the actual dynamics to be insignificant.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1bUXjkjsaat1VTbNVxp5CZQIoytxQpfnq\" width=\"400\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWBgAkumvk9i"
      },
      "source": [
        "# E-Level\n",
        "\n",
        "In this section, we will:\n",
        "\n",
        "*   create a discrete, finite-state representation of an environment\n",
        "*   use state-of-the-art tools to translate LTL formulae into BÃ¼chi-Automata\n",
        "*   combine the two to find a path in the environment that satisfies our LTL formula\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge7cKjBO-zes"
      },
      "source": [
        "## Workspace Model\n",
        "\n",
        "In order to facilitate high-level planning, we will create a **finite** and **discrete** representation of our workspace, namely a **transition system**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqXeULMSrXZf"
      },
      "source": [
        "### Theory - Transition Systems\n",
        "In the following sections, you will discretize our continuous workspace model into a transition system.\n",
        "\n",
        "Formally, a labelled transition system is defined as a tuple\n",
        "\n",
        "$$T=(S, Act, \\xrightarrow{}, s_0, \\mathit{AP}, L)$$\n",
        "where \n",
        "* $S$ is a finite set of states, \n",
        "* $Act$ is a finite set of inputs, \n",
        "* $\\xrightarrow{} : S \\times Act \\times S$ is the transition function,  \n",
        "* $s_0$ is the initial state, \n",
        "* $\\mathit{AP}$ is a finite set of atomic propositions and \n",
        "* $L : S \\xrightarrow{} 2^{\\mathit{AP}}$ is a state labeling function.\n",
        "\n",
        "Here, we have an abstract example of a transition system with four states $s_0$ to $s_3$ depicted as circles. The initial state $s_0$ is marked with an incoming arrow. Each arrow between two states is a transition captured by the transition function, like $\\delta(s_3, act_1) = s_2$ or $\\delta(s_3, act_2) = s_1$. In each state, you choose an action to perform and the transition system changes state accordingly.\n",
        "\n",
        "Each state is labelled by the labelling function $L$, which assigns to a state the atomic propositions which hold true in that state. $L(s_0) = \\{a,b\\}$ meaning that both $a$ and $b$ hold true in that state.\n",
        "\n",
        "![image](https://drive.google.com/uc?id=1Rm3UHih5dBpGdI9Fcs4aQfh0F2HSKrDw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGs43V4vq7Yg"
      },
      "source": [
        "### Theory - Paths and Traces\n",
        "\n",
        "* An (infinite) **path** $\\pi$ on a transition system is a sequence of states $s_0s_1s_2 \\dots$ such that $s_0$ is the initial state and $\\forall i\\geq 0 \\;: \\exists a \\in Act: s_{i+1} \\in \\delta(s_i, a)$.\n",
        "\n",
        "* A **trace** of a given path $\\pi = s_0s_1s_2\\dots$ is the sequence of labels $\\tau(\\pi)=L(s_0)L(s_1)L(s_2)\\dots$.\n",
        "\n",
        "* The traces of a transition system are thus (infinite) words on the alphabet $2^{\\mathit{AP}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9VvDTwPVc9R"
      },
      "source": [
        "### Workspace Definition\n",
        "\n",
        "First, let's define the workspace. We assume a rectangular subset of $\\mathbb{R}^2$ with so-called regions of interest defined as 2D polygons. We define the polygons through their vertices. Some of the regions are static obstacles, which we will cut out from our representation. Those regions have a `self.hole` defined during construction. You can also see that the regions have a `self.cost_per_unit` attribute, but you can ignore that for the E-level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdMHBzQU-7oR"
      },
      "outputs": [],
      "source": [
        "from shapely.geometry import Polygon, Point\n",
        "\n",
        "default_cost_per_unit = 1\n",
        "\n",
        "class RegionOfInterest:\n",
        "  def __init__(self, name, points, hole=None, cost_per_unit=default_cost_per_unit):\n",
        "    self.name = name\n",
        "    self.points = points\n",
        "    self.hole = hole\n",
        "    self.poly = Polygon(points)\n",
        "    self.cpu = cost_per_unit\n",
        "  \n",
        "  def contains(self, x, y):\n",
        "    result = self.poly.contains(Point(x, y))\n",
        "    if isinstance(result, bool):\n",
        "      return result\n",
        "    else:\n",
        "      return result[0]\n",
        "\n",
        "# define workspace bounds\n",
        "xmin = 0\n",
        "xmax = 10\n",
        "ymin = 0\n",
        "ymax = 10\n",
        "\n",
        "# define regions of interest\n",
        "rois = [\n",
        "    RegionOfInterest(\n",
        "        name=\"staircase\",\n",
        "        points=[(0,10), (3,10), (3,8), (0,8)], \n",
        "        hole=(1.5,9)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"charge\",\n",
        "        points=[(3,9), (3,10), (4,10), (4,9)], \n",
        "    ), \n",
        "    RegionOfInterest(\n",
        "        name=\"wall1\",\n",
        "        points=[(6,4), (6,5), (9,5), (9,4)], \n",
        "        hole=(8,4.5)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"wall2\",\n",
        "        points=[(4,1), (4,4), (5,4), (5,1)], \n",
        "        hole=(4.5,2)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"wall3\",\n",
        "        points=[(2,4), (2,5), (5,5), (5,4)], \n",
        "        hole=(3.5,4.5)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"wall4\",\n",
        "        points=[(0,4), (0,5), (1,5), (1,4)], \n",
        "        hole=(0.5,4.5)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"wall5\",\n",
        "        points=[(6,5), (6,9), (7,9), (7,5)], \n",
        "        hole=(6.5,7)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"rooma\",\n",
        "        points=[(0,0), (0,4), (4,4), (4,0)], \n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"roomb\",\n",
        "        points=[(7,5), (7,10), (10,10), (10,5)], \n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"roomc\",\n",
        "        points=[(5,0), (5,4), (10,4), (10,0)], \n",
        "    ),\n",
        "    \n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxyxBuphw5is"
      },
      "source": [
        "In order to create a discrete, finite representation of this workspace, we create a triangulation of the workspace. To accomplish this, we use the triangulation library [Triangle](https://www.cs.cmu.edu/~quake/triangle.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV5SqU7aDbSm"
      },
      "source": [
        "#### Triangle Parsing Functions\n",
        "\n",
        "In this section are the functions required to write and parse our data into and out of files compatible with the Triangle library. You do not need to deeply understand these, but feel free to take a look!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAnL5-eFDIdR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "CREATE INPUT FILES READABLE BY TRIANGLE\n",
        "\"\"\"\n",
        "# creates a .poly file from workspace and obstacles according to https://www.cs.cmu.edu/~quake/triangle.poly.html\n",
        "def workspace_to_poly_file(xmin, xmax, ymin, ymax, regions):\n",
        "  # vertices of the mesh - workspace corners and obstacle points\n",
        "  num_vert = 4 + sum( [ len(reg.points) for reg in regions])\n",
        "  vert_header = \"#vertices\\n%i 2 0 0\\n\"%num_vert\n",
        "  vert_str = \"0 %i %i\\n\"%(xmin, ymin)\n",
        "  vert_str += \"1 %i %i\\n\"%(xmin, ymax)\n",
        "  vert_str += \"2 %i %i\\n\"%(xmax, ymax)\n",
        "  vert_str += \"3 %i %i\\n\"%(xmax, ymin)\n",
        "\n",
        "  vert_id = 4;\n",
        "  for reg in regions:\n",
        "    for (x,y) in reg.points:\n",
        "      vert_str += \"%i %f %f\\n\"%(vert_id, x, y)\n",
        "      vert_id += 1\n",
        "  \n",
        "  # line segments that will be enforced in the triangulation\n",
        "  num_seg = num_vert # since all shapes are closed\n",
        "  seg_header = \"#segments\\n%i 0\\n\"%num_seg\n",
        "  seg_str = \"0 0 1\\n1 1 2\\n2 2 3\\n3 3 0\\n\" # workspace bounds\n",
        "\n",
        "  seg_id = 4\n",
        "  vert_id = 4\n",
        "  for reg in regions:\n",
        "    for i in range(len(reg.points)):\n",
        "      from_id = vert_id + i\n",
        "      to_id = vert_id + i + 1 if i+1 < len(reg.points) else vert_id\n",
        "      seg_str += \"%i %i %i\\n\"%(seg_id, from_id, to_id)\n",
        "      seg_id += 1\n",
        "    vert_id += len(reg.points)\n",
        "\n",
        "  # holes\n",
        "  num_holes = 0\n",
        "  hole_str = \"\"\n",
        "  for reg in regions:\n",
        "    if reg.hole is not None:\n",
        "      hole_str += \"%i %f %f\\n\"%(num_holes, reg.hole[0], reg.hole[1])\n",
        "      num_holes += 1\n",
        "  hole_header = \"#holes\\n%i\\n\"%num_holes\n",
        "\n",
        "  with open(\"workspace.poly\", \"w\") as f:\n",
        "    f.write(vert_header + vert_str + seg_header + seg_str + hole_header + hole_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxff48_rcmVH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "PARSE TRIANGLE OUTPUT FILES\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# assumes [file_name].1.node and [file_name].1.ele to exist\n",
        "def parse_triangle(file_name=\"workspace\"):\n",
        "  vertices = []\n",
        "  faces = []\n",
        "  \n",
        "  # read vertex positions\n",
        "  with open(file_name+\".1.node\", encoding = 'utf-8') as f:\n",
        "    # first line contains info about number of vertices etc, see: https://www.cs.cmu.edu/~quake/triangle.node.html\n",
        "    first_line = next(f).strip().split()\n",
        "    assert len(first_line) == 4\n",
        "    assert first_line[1] == \"2\" # 2d vertices\n",
        "    num_vert = int(first_line[0])\n",
        "    for line in f:\n",
        "      values = line.strip().split()\n",
        "      if values[0].isnumeric():\n",
        "        x = float(values[1])\n",
        "        y = float(values[2])\n",
        "        vertices.append((x,y))\n",
        "    assert num_vert == len(vertices)\n",
        "  \n",
        "  # read face indices\n",
        "  with open(file_name+\".1.ele\", encoding = 'utf-8') as f:\n",
        "    # first line contains info about number of vertices etc, see: https://www.cs.cmu.edu/~quake/triangle.ele.html\n",
        "    first_line = next(f).strip().split()\n",
        "    assert len(first_line) == 3\n",
        "    assert first_line[1] == \"3\" # each triangle has 3 nodes\n",
        "    num_face = int(first_line[0])\n",
        "\n",
        "    for line in f:\n",
        "      values = line.strip().split()\n",
        "      if values[0].isnumeric():\n",
        "        assert len(values) == 4\n",
        "        faces.append((int(values[1]), int(values[2]), int(values[3])))\n",
        "    assert num_face == len(faces)\n",
        "\n",
        "  return np.array(vertices), np.array(faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLwvRf0EEoi1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "CALL TRIANGLE\n",
        "\"\"\"\n",
        "import subprocess\n",
        "\n",
        "def call_triangle(filename=\"workspace.poly\", max_area=None):\n",
        "  options = [\"triangle/triangle\", \"-p\", \"-q\", filename, \"-D\"]\n",
        "  if max_area is not None:\n",
        "    options.insert(1, \"-a%f\"%max_area)\n",
        "  subprocess.run(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo63iIsEEFaD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "VIZUALIZE RESULTS\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import PatchCollection\n",
        "import matplotlib.patches as pt\n",
        "\n",
        "def centroid(points):\n",
        "  x = 0\n",
        "  y = 0\n",
        "  for p in points:\n",
        "    assert len(p) == 2\n",
        "    x += p[0]\n",
        "    y += p[1]\n",
        "  x /= len(points)\n",
        "  y /= len(points)\n",
        "  return (x, y)\n",
        "\n",
        "def normalized_alpha_by_cost(points, rois, max_cost):\n",
        "  default_alpha = 0.4 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "  min_cost = 1\n",
        "  min_alpha = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "  max_alpha = 0.7 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "  # if all costs are the same\n",
        "  if max_cost == min_cost:\n",
        "    return default_alpha\n",
        "  # find cost of this face\n",
        "  cost = None\n",
        "  for roi in rois:\n",
        "    x,y = centroid(points)\n",
        "    if roi.contains(x,y):\n",
        "      cost = roi.cpu\n",
        "      break\n",
        "  # does not belong to a region of interest, default cost\n",
        "  if cost is None:\n",
        "    return min_alpha\n",
        "  # otherwise linear map from cost in [min_cost, max_cost] to [min_alpha, max_alpha]\n",
        "  alpha = (cost - min_cost)*(max_alpha-min_alpha)/(max_cost-min_cost) + min_alpha\n",
        "  return alpha\n",
        "\n",
        "def viz_mesh(vertices, faces, rois, highlight=[]):\n",
        "  # find highest cost area\n",
        "  highest_cost = 1\n",
        "  for roi in rois:\n",
        "    if roi.cpu > highest_cost:\n",
        "      highest_cost = roi.cpu\n",
        "\n",
        "  patches = []\n",
        "  for (i, f) in enumerate(faces):\n",
        "    # get coords for the face\n",
        "    coords = np.zeros(6).reshape(3,2)\n",
        "    for j in range(3):\n",
        "      coords[j] = vertices[f[j]]\n",
        "    # default faces are blue, path highlight is red, roi faces are yellow\n",
        "    color = \"b\"\n",
        "    if i in highlight:\n",
        "      color = \"r\"\n",
        "    else:\n",
        "      for roi in rois:\n",
        "        x,y = centroid(coords)\n",
        "        if roi.contains(x,y):\n",
        "          color = \"y\"\n",
        "          break\n",
        "    # depending on region cost, appropriate alpha is chosen\n",
        "    alpha = normalized_alpha_by_cost(coords, rois, highest_cost)\n",
        "    polygon = pt.Polygon(coords, closed=True, fill=True, facecolor=color, edgecolor=color, alpha=alpha)\n",
        "    patches.append(polygon)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  p = PatchCollection(patches, match_original=True)\n",
        "  ax.add_collection(p)\n",
        "  plt.scatter(vertices[:, 0], vertices[:, 1])\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2ecFImUD3UV"
      },
      "source": [
        "### Calling Triangle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqx-q_aeD8ht"
      },
      "outputs": [],
      "source": [
        "# create input file\n",
        "workspace_to_poly_file(xmin, xmax, ymin, ymax, regions=rois)\n",
        "# call triangle\n",
        "max_area = 1.5 #@param {type:\"slider\", min:0.1, max:5.0, step:0.1}\n",
        "call_triangle(max_area=max_area)\n",
        "# parse output\n",
        "vert, faces = parse_triangle()\n",
        "# vizualize the result\n",
        "viz_mesh(vert, faces, rois)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q8KTMIt4P4E"
      },
      "source": [
        "### Exercise - Creating the Transition System\n",
        "\n",
        "Next, we will need to translate this mesh into a transition system. We will be using [NetworkX](https://networkx.org/) to represent our TS. \n",
        "\n",
        "`vert` is a list of vertices. Each entry in the list represents a 2D point of the mesh.\n",
        "`faces` is a list of faces (triangles). Each face is defined through three vertices. Each entry in the list is an index of the corresponding vertex in `vert`.\n",
        "\n",
        "**Exercise:**\n",
        "* Create a state for each face in `faces`\n",
        "* Create transitions between neighbouring faces. This will represent the possibility to travel between these areas.\n",
        "\n",
        "**Hints:** \n",
        "* Two faces are adjacent if they share two vertices. \n",
        "* If face a is adjacent to b, then b is also adjacent to a.\n",
        "* Each face is \"adjacent\" to itself; The autonomous system can stay in an area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBhCDHNw4O-C"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "def ts_from_triang(vert, faces):\n",
        "  # create a networkx directed graph, see https://networkx.org/documentation/stable/reference/classes/digraph.html\n",
        "  ts = nx.DiGraph()\n",
        "  # PUT YOUR SOLUTION HERE \n",
        "  # for example by using methods like:\n",
        "  # ts.add_node(node_id, associated_data=some_data)\n",
        "  # ts.add_edge(node1, node2)\n",
        "  return ts\n",
        "\n",
        "ts = ts_from_triang(vert, faces)\n",
        "assert(len(ts.nodes()) == len(faces))\n",
        "print(\"Number of states:\", len(ts.nodes()))\n",
        "print(\"Number of transitions:\", len(ts.edges()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GgNGacbcE7U"
      },
      "source": [
        "### Exercise - Labelling States\n",
        "\n",
        "Next, we will define atomic propositions and label the states.\n",
        "\n",
        "**Exercise:**\n",
        "* Use the names of the regions of interest to define the atomic propositions $AP$.\n",
        "* Label all states by checking in which regions of interest the face belongs to.\n",
        "* Choose one the faces in `charge` as the initial state. Store it in `ts.graph[\"init\"]`.\n",
        "\n",
        "**Hints:**\n",
        "* You can store information about the graph like so `ts.graph[\"key\"] = some_cool_data`.\n",
        "* You can store information about a specific node like so `ts.nodes[node][\"labels\"] = label_data`.\n",
        "* Regions of interest can overlap.\n",
        "* Regions of interest can have multiple faces.\n",
        "* Each region of interest defined above has a `self.poly` attribute, which stores a [Shapely Polygon](https://shapely.readthedocs.io/en/stable/manual.html#polygons). You can use [the contains() method](https://shapely.readthedocs.io/en/stable/manual.html#object.contains) to check if a geometric shape or point is inside a polygon.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nVw4E84udfU"
      },
      "outputs": [],
      "source": [
        "def label_ts(ts, rois):\n",
        "  # PUT YOUR SOLUTION HERE\n",
        "  # manipulate the given TS, adding label information to states\n",
        "  # save info on all possible labels\n",
        "  # label the states\n",
        "  pass\n",
        "\n",
        "label_ts(ts, rois)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fapicWEy3Hcw"
      },
      "source": [
        "### Visualizing the Transition System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nIl9Xxd17Lb"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create a position for each state (center of face)\n",
        "pos = {}\n",
        "for i, face in enumerate(faces):\n",
        "    points = []\n",
        "    for fid in face:\n",
        "      points.append(vert[fid])\n",
        "    pos[i] = np.asarray(centroid(points))\n",
        "nx.draw(ts, pos=pos)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R90ec7F6A-6B"
      },
      "source": [
        "## Specification Language\n",
        "\n",
        "To specify the desired system behaviour, we use **Linear Temporal Logic (LTL)**. Originally proposed for the formal analysis of computer programs, LTL was introduced in 1977 by the computer scientist [Amir Pnueli](https://en.wikipedia.org/wiki/Amir_Pnueli)[1]. With LTL, we can encode formulae about the future of paths, e.g., a condition will eventually be true, a condition will be true until another fact becomes true, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtzwRjZ6r2Kg"
      },
      "source": [
        "### Theory - Linear Temporal Logic\n",
        "\n",
        "LTL formulae are interpreted over linear, infinite execution traces, for example those produced by a transition system. Like in the transition system definition, $AP$ is a set of propositions.\n",
        "\n",
        "$$\n",
        "    \\phi := true\\;|\\;\n",
        "    a\\;|\\;\n",
        "    \\neg \\phi\\;|\\;\n",
        "    \\phi_1 \\wedge \\phi_2\\;|\\;\n",
        "    X \\phi \\;|\\;\n",
        "    \\phi \\, U \\phi, \n",
        "    \\quad a \\in \\mathit{AP}\n",
        "$$\n",
        "\n",
        "The full power of propositional logic is obtained through the operators $\\neg$ and $\\wedge$. Operators $\\vee, \\xrightarrow{}, \\leftrightarrow{}$ are defined as usual:\n",
        "* $a \\vee b \\equiv \\neg (\\neg a \\wedge \\neg b)$\n",
        "* $a \\xrightarrow{} b \\equiv \\neg a \\vee b$\n",
        "* $a \\leftrightarrow{} b \\equiv (a \\wedge b) \\vee (\\neg b \\wedge \\neg a)$ \n",
        "\n",
        "$X$ is the next-operator, representing something holding in the next step. $U$ is the until-operator, requiring $\\phi_1$ to hold until $\\phi_2$ holds. For our purposes, the temporal operators $F$ and $G$ are practical to use. They are defined like this:\n",
        "\n",
        "* $F \\phi=true\\,U \\phi$ represents $\\phi$ holding **eventually** in the future and \n",
        "* $G \\phi = \\neg F \\neg\\phi$ **always** holding from now on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOtwMrfCaCV6"
      },
      "source": [
        "## LTL to BÃ¼chi-Automaton\n",
        "\n",
        "One of the key benefits of LTL is that for any valid formula, you can construct a **BÃ¼chi Automaton** that exactly decides between the sequences of propositions that satisfy the formula and those that don't [2]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIYMDHLbutYC"
      },
      "source": [
        "### Theory - Infinite Word Automata\n",
        "An **BÃ¼chi automaton** over the alphabet $\\Sigma$ is a tuple \n",
        "\n",
        "$$A=(Q, \\Sigma, \\delta, q_0, F)$$\n",
        "where:\n",
        "\n",
        "* $Q$ is a finite set of states, \n",
        "* $\\Sigma$ is a finite set of symbols (in this tutorial always $\\Sigma = 2^\\mathit{AP}$, \n",
        "* $\\delta : Q \\times \\Sigma \\xrightarrow{} 2^Q$ is a transition function, \n",
        "* $q_0$ is the initial state, and \n",
        "* $F \\subseteq Q$ is a finite set of *accepting* states.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHyPbAlNwNqb"
      },
      "source": [
        "### Theory - Runs, Acceptance and Determinism\n",
        "\n",
        "* A **run** of the infinite word automaton $A$ on a word $\\sigma = \\sigma_0\\sigma_1\\sigma_2\\dots \\in \\Sigma^\\omega$ is an infinite sequence of states $r = q_0q_1q_2\\dots \\in Q^\\omega$ with $q_\\mathit{ini}$ being the initial state and $\\forall i \\geq 0: q_{i+1} \\in \\delta(q_i, \\sigma_i)$. Given a word $\\sigma$, we define the set of all possible runs of $A$ on $\\sigma$ as $\\mathit{Runs}_A(\\sigma)$. \n",
        "\n",
        "* We say a run is **accepting** if it visits a state in $F$ infinitely often.\n",
        "\n",
        "* We say the automaton **accepts** a word $\\sigma$ if one of the runs in $\\mathit{Runs}_A(\\sigma)$ is accepting.\n",
        "\n",
        "* When $|\\delta(q, \\sigma)| <= 1, \\forall q \\in Q, \\forall \\sigma \\in \\Sigma$, we call the automaton **deterministic**. As a consequence, $|\\mathit{Runs}_A(\\sigma)| <= 1, \\forall \\sigma \\in \\Sigma$. In the rest of this document, we abbreviate non-deterministic BÃ¼chi Automaton with **NBA**.\n",
        "\n",
        "* When $|\\delta(q, \\sigma)| > 0, \\forall q \\in Q, \\forall \\sigma \\in \\Sigma$, we call the automaton **complete**.\n",
        "\n",
        "You can imagine that we sequentially feed an infinite word into the BÃ¼chi automaton, symbol by symbol. The automaton takes the incoming next symbol and changes state accordingly. If there are multiple edges to take (non-determinism), we have to consider both options. If there is no option (non-completeness), the run simply is discarded. A word is accepted if one of the infinite paths visits an accepting state infinitely often.\n",
        "\n",
        "As mentioned before, we can construct a NBA for every LTL formula $\\phi$ such that the words that satisfy the the formula are exactly the words that get accepted by the the NBA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nku-GIVei606"
      },
      "source": [
        "### Automaton Construction via LTL3BA\n",
        "\n",
        "To generate our NBA from a given LTL formula, we use [LTL3BA](https://sourceforge.net/projects/ltl3ba/) [3]. More on the theory behind the automaton construction can be found in [2].\n",
        "\n",
        "LTL formulas are given as strings with the following formatting:\n",
        "```\n",
        "Propositonal Symbols:\n",
        "  true, false\n",
        "  any lowercase string\n",
        "Boolean operators (no priority, use parentheses):\n",
        "  !   (negation)\n",
        "  ->  (implication)\n",
        "  <-> (equivalence)\n",
        "  &&  (and)\n",
        "  ||  (or)\n",
        "Temporal operators (no priority, use parentheses):\n",
        "  G   (always)\n",
        "  F   (eventually)\n",
        "  U   (until)\n",
        "  X   (next)\n",
        "```\n",
        "There is no guarantee that the generated automaton will be deterministic or complete. The result is parsed into a Networkx directed graph:\n",
        "* `nba.graph[\"accept\"]` stores the accepting states\n",
        "* `nba.graph[\"init\"]` stores the initial state\n",
        "* `nba.edges[q1, q2][\"guard\"]`: Each edge has a boolean [SymPy](https://www.sympy.org/en/index.html) expression that represents when this edge can be taken\n",
        "* You can evaluate SymPy expressions via `guard.subs({\"a\": True, \"b\": False})`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXcilMICBEW_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "PARSE LTL3BA OUTPUT\n",
        "\"\"\"\n",
        "\n",
        "import subprocess\n",
        "import networkx as nx\n",
        "import re\n",
        "from sympy.parsing.sympy_parser import parse_expr\n",
        "\n",
        "def ltl_to_nba(formula, print_ltl3ba=False):  \n",
        "  raw = subprocess.check_output([\"ltl3ba-1.1.3/ltl3ba\", \"-f\",  formula])\n",
        "  lines = raw.decode('utf-8').split(\"\\n\")\n",
        "  nba = nx.DiGraph()\n",
        "  nba.graph[\"accept\"] = []\n",
        "\n",
        "  for line in lines:\n",
        "    if print_ltl3ba:\n",
        "      print(line) \n",
        "    #we skip unnecessary lines\n",
        "    if \"never\" in line or \"}\" in line or len(line) == 0:\n",
        "      continue\n",
        "    # this line is a state\n",
        "    if line[0] != \"\\t\":\n",
        "      state = line.strip(\":\")\n",
        "      nba.add_node(state)\n",
        "      if \"init\" in state:\n",
        "        nba.graph[\"init\"] = state\n",
        "      if \"accept\" in state:\n",
        "        nba.graph[\"accept\"].append(state)\n",
        "    else:\n",
        "      # edge descriptions\n",
        "      if line[1] == \":\":\n",
        "        guard = re.search(\"\\t:: (.*) -> goto\", line).group(1).replace(\"||\", \"|\").replace(\"&&\", \"&\").replace(\"!\", \"~\")\n",
        "        parsed_guard = parse_expr(guard)\n",
        "        # print(parsed_guard, parsed_guard.subs({\"a\": True, \"b\": False}))\n",
        "        state_to = re.search(\"-> goto (.*)\", line).group(1)\n",
        "        nba.add_edge(state, state_to, guard=parsed_guard)\n",
        "      # this state accepts all inputs - self loop with true guard\n",
        "      if line == \"\\tskip\":\n",
        "        nba.add_edge(state, state, guard=parse_expr(\"True\"))\n",
        "  return nba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SflvQXuFJ3d2"
      },
      "source": [
        "### Exercise - BÃ¼chi Automata\n",
        "\n",
        "**Exercise:**\n",
        "* Generate the BÃ¼chi Automaton for $\\phi = F G \\,a$.\n",
        "* Examine the output. How many states does it have? How many edges?\n",
        "* Is it deterministic? Why? Why not?\n",
        "* Is it complete? Why? Why not?\n",
        "* Give each one example of an (infinite) accepted word and a rejected word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Mj4syckEkt"
      },
      "source": [
        "## Finding a Solution\n",
        "\n",
        "To find a series of actions in the transition system $T$ such that the resulting trace satisfies $\\phi$, we construct a **product automaton** that simultaneously keeps track of both $T$ and the BÃ¼chi Automaton $A$ created from $\\phi$. Then, we will find a so-called **lasso path** on this product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gYTsmsL3fCQ"
      },
      "source": [
        "### Theory - Product Automaton\n",
        "\n",
        "Given a transition system \n",
        "$$T = (S,Act,\\xrightarrow{},s_0,\\mathit{AP},L)$$ \n",
        "and a NBA\n",
        "$$A = (Q, 2^{\\mathit{AP}}, \\delta, q_0, F)$$\n",
        "the product automaton is a tuple \n",
        "$$P = (Q_p, \\Sigma_p, \\delta_p, q_{p,0}, F_p)$$\n",
        "where:\n",
        "* $Q_p \\subseteq S \\times Q$ is a finite set of states; Each state holds information about the current state of the transition system as well as the current state of the NBA, \n",
        "* $\\Sigma_p = \\mathit{Act}$ is a finite set actions (directly from the transition system), \n",
        "* $\\delta_p : Q_p \\times \\mathit{Act} \\xrightarrow{} 2^{Q_p}$ is a transition function (explained below), \n",
        "* $q_{0,p} = (s_0, q_0)$ is the initial state, and \n",
        "* $F_p = \\{(s,q) \\in Q_p \\;|\\; q\\in F\\}$ is a finite set of *accepting* states.\n",
        "\n",
        "The transition function $\\delta_p$ is defined as follows:\n",
        "\n",
        "$$\\delta_p((s,q),\\mathit{act}) = \\{(s',q')\\in Q_p\\;|\\; (s, \\mathit{act},s') \\in \\xrightarrow{} \\text{ and } (q, L(s'), q')  \\in \\delta\\}$$\n",
        "\n",
        "Basically, from a state (s,q), you choose a valid action and advance the state of the transition system $s \\xrightarrow{\\mathit{act}} s'$ and then check what propositions hold true in the new state through the labelling function $L(s')$. Based on these propositions, you advance the state of the BÃ¼chi automaton $u \\xrightarrow{L(s')} u'$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-XtSuWiKXtA"
      },
      "source": [
        "### Exercise - Product Automaton\n",
        "\n",
        "**Exercise:**\n",
        "* Write a function that constructs the product automaton $P$ when given a transition system and a bÃ¼chi automaton.\n",
        "* Construct the product automaton with the transition system you created above and the formula `\"(G F goal1) && (G F goal2)\"`\n",
        "* Keep track of initial state in `prod.graph[\"init\"]` and accepting states in `prod.graph[\"accept\"]`\n",
        "\n",
        "**Hints:**\n",
        "* Start by creating a new `nx.DiGraph` and add the initial state.\n",
        "* NetworkX graphs can use tuples as states, `graph.add_node((ts_state, ba_state))` is valid.\n",
        "* Create a queue where you add states that you have to work on.\n",
        "* Starting from the initial state, make a valid move in the transition system and see how it can advance the state in the bÃ¼chi automaton. Add newly created states to the queue. create appropriate edges between states.\n",
        "* Repeat until the queue is empty.\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIeeD4hkIaf"
      },
      "outputs": [],
      "source": [
        "import queue\n",
        "\n",
        "def product_automaton(ts, nba):\n",
        "  prod = nx.DiGraph()\n",
        "  prod.graph[\"accept\"] = []\n",
        "\n",
        "  # queue of open states\n",
        "  que = queue.Queue()\n",
        "  prod_init = (ts.graph[\"init\"], nba.graph[\"init\"])\n",
        "  prod.graph[\"init\"] = prod_init\n",
        "  que.put(prod_init)  # initialize the queue\n",
        "\n",
        "  # work the queue\n",
        "  while not que.empty():\n",
        "    prod_from = que.get()\n",
        "    ts_from = prod_from[0]\n",
        "    nba_from = prod_from[1]\n",
        "\n",
        "    # PUT YOUR SOLUTION HERE\n",
        "    # for all valid steps in the TS, check how it changes the NBA state\n",
        "    # maybe create a new state and put new states into the queue\n",
        "\n",
        "  return prod"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nba = ltl_to_nba(\"(G F rooma) && (G F roomb) && (G F roomc)\")\n",
        "prod = product_automaton(ts, nba)"
      ],
      "metadata": {
        "id": "BoFj3ivz-WP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCdUGXstOaV4"
      },
      "source": [
        "### Lasso Path\n",
        "\n",
        "To find a finite representation of an infinite path, we use the notion of a lasso path. Remember, a path between two states is a sequence of states where between each two sequential states, there exists a transition.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://static.vecteezy.com/ti/gratis-vektor/p3/5263875-lasso-rep-for-fanga-djur-gratis-vector.jpg\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "A lasso path is divided into two parts: The **prefix** that goes from the start of the lasso to the knot and the **suffix** that describes the loop at the end of the lasso.\n",
        "\n",
        "For our case, we can find an infinite accepting path on the product by finding a circular path containing any accepting state (the suffix) and a path from the initial state to this accepting state (the prefix).\n",
        "\n",
        "The following code:\n",
        "* Finds circular path in the product automaton with an accepting state in it.\n",
        "* Finds paths from the initial state to each accepting state.\n",
        "* Project the paths back to a sequence of triangle ids in `face`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqNGAJvRKfOn"
      },
      "outputs": [],
      "source": [
        "def min_suffixes(prod, weight=None):\n",
        "  acc_cycles = {}\n",
        "  for acc_state in prod.graph[\"accept\"]:\n",
        "    shortest_len = float('inf')\n",
        "    for succ in prod.successors(acc_state):\n",
        "      path = nx.shortest_path(prod, source=succ, target=acc_state, weight=weight)\n",
        "      if len(path) < shortest_len:\n",
        "        shortest_len = len(path)\n",
        "        shortest = [acc_state]\n",
        "        shortest.extend(path)\n",
        "        acc_cycles[acc_state] = shortest\n",
        "  return acc_cycles\n",
        "\n",
        "def min_prefixes(prod, weight=None):\n",
        "  prefixes = {}\n",
        "  for acc_state in prod.graph[\"accept\"]:\n",
        "    prefix = nx.shortest_path(prod, source=prod.graph[\"init\"], target=acc_state, weight=weight)\n",
        "    prefixes[acc_state] = prefix\n",
        "  return prefixes\n",
        "    \n",
        "# compute suffixes and prefixes for all accepting states\n",
        "suffixes = min_suffixes(prod)\n",
        "prefixes = min_prefixes(prod)\n",
        "\n",
        "arbitrary_acc_state = prod.graph[\"accept\"][0]\n",
        "prefix_path = [state[0] for state in prefixes[arbitrary_acc_state]]\n",
        "suffix_path = [state[0] for state in suffixes[arbitrary_acc_state]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGYvXKNvR6Q"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "If you provide a sequence of triangle ids matching those in `face` as `prefix_path` and `suffix_path`, you should see cool animations of your solutions below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX6HRvrpTpq3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import PatchCollection\n",
        "from matplotlib.patches import Polygon\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# always returns a value between 0 (cold) and 1(hot)\n",
        "def interp_value(face_id, path, progress):\n",
        "  decay = 5 # how many steps should the faces take to cool down completely\n",
        "  # find this triangle's index on the path\n",
        "  occurences = [i for i, x in enumerate(path) if x == face_id]\n",
        "  values = []\n",
        "  for path_pos in occurences:\n",
        "    # too early\n",
        "    if progress < path_pos:\n",
        "      values.append(0)\n",
        "      continue\n",
        "    # too late\n",
        "    if progress > path_pos + decay:\n",
        "      values.append(0)\n",
        "      continue\n",
        "    # right inbetween\n",
        "    lower = path_pos\n",
        "    upper = path_pos + decay\n",
        "    interp = (upper - progress)/decay\n",
        "    values.append(interp)\n",
        "\n",
        "  if not values:\n",
        "    return 0\n",
        "  return max(values)\n",
        "   \n",
        "def animate_path(vertices, faces, path):\n",
        "  # constants\n",
        "  fps = 10\n",
        "  step_interval = 500\n",
        "  ms_per_frame = 1000 / fps\n",
        "  total_frames = (int)(len(path) * step_interval / ms_per_frame)\n",
        "  hot = mcolors.to_rgba(\"crimson\")\n",
        "  cold = mcolors.to_rgba(\"blue\")\n",
        "  # find highest cost area\n",
        "  highest_cost = 1\n",
        "  for roi in rois:\n",
        "    if roi.cpu > highest_cost:\n",
        "      highest_cost = roi.cpu\n",
        "  # create patch for every triangle and register with the figure\n",
        "  patches = []\n",
        "  for (i, face) in enumerate(faces):\n",
        "    coords = np.zeros(6).reshape(3,2)\n",
        "    for j in range(3):\n",
        "      coords[j] = vert[face[j]]\n",
        "    color = \"b\"\n",
        "    alpha = normalized_alpha_by_cost(coords, rois, highest_cost)\n",
        "    polygon = Polygon(coords, closed=True, fill=True, facecolor=color, edgecolor=color, alpha=alpha)\n",
        "    patches.append(polygon)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  p = PatchCollection(patches, alpha=0.4, match_original=True)\n",
        "  ax.add_collection(p)\n",
        "  plt.scatter(vert[:, 0], vert[:, 1])    \n",
        "\n",
        "  def update(frame):\n",
        "    progress = frame * ms_per_frame / step_interval\n",
        "    step = (int)(progress)\n",
        "    coll = ax.collections[0]\n",
        "    facecolors = coll.get_facecolors()\n",
        "    # update face colors\n",
        "    for i in range(len(facecolors)):\n",
        "      interp = interp_value(i, path, progress)\n",
        "      facecolors[i] = [(1-interp)*c + interp*h for c, h in zip(cold, hot)]\n",
        "    coll.set_facecolor(facecolors)\n",
        "\n",
        "  ani = FuncAnimation(fig, update, frames=total_frames, interval=ms_per_frame)\n",
        "  return ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5duL4QH4xZ-M"
      },
      "source": [
        "### Prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLuI_sXYxdNu"
      },
      "outputs": [],
      "source": [
        "viz_mesh(vert, faces, rois, highlight=prefix_path)\n",
        "animate_path(vert, faces, prefix_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsbd_B9dxf03"
      },
      "source": [
        "### Suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt4UA2uCxg1i"
      },
      "outputs": [],
      "source": [
        "viz_mesh(vert, faces, rois, highlight=suffix_path)\n",
        "animate_path(vert, faces, suffix_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7uw2O1ovouz"
      },
      "source": [
        "# C-Level\n",
        "\n",
        "In this section, we will expand our existing model of the environment with travel costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6iM1LWo76W1"
      },
      "source": [
        "## Expanding the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OeOKvkZ4iTt"
      },
      "source": [
        "### Theory - Weighted Transition Systems\n",
        "A weighted, labelled transition system is defined as a tuple\n",
        "\n",
        "$$T=(S, Act, \\xrightarrow{}, s_0, \\mathit{AP}, L, w)$$\n",
        "where \n",
        "* $S$ is a finite set of states, \n",
        "* $Act$ is a finite set of inputs, \n",
        "* $\\xrightarrow{} : S \\times Act \\times S$ is the transition function,  \n",
        "* $s_0$ is the initial state, \n",
        "* $\\mathit{AP}$ is a finite set of atomic propositions,\n",
        "* $L : S \\xrightarrow{} 2^{\\mathit{AP}}$ is a state labeling function and\n",
        "* $w: S \\times \\mathit{Act} \\xrightarrow{} \\mathbb{R}^+$ is the weight function. \n",
        "\n",
        "Except for the weight function, this is identical to a regular Transition System. The weight function assigns each edge a cost. For this tutorial, we restrict ourself for **positive** values for the weight function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoQc7Dat-UVX"
      },
      "source": [
        "### Regions of Different Cost\n",
        "\n",
        "Here, we define a new set of regions of interest with a new region somewhere in the center that is very costly to go through (so our future plan will navigate around it). The default cost per unit is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tddo9MD0Oryk"
      },
      "outputs": [],
      "source": [
        "# define regions of interest\n",
        "rois_w = [\n",
        "    RegionOfInterest(\n",
        "        name=\"obs1\",\n",
        "        points=[(1,1), (1,2), (2,2), (2,1)], \n",
        "        hole=(1.5,1.5)\n",
        "    ), \n",
        "    RegionOfInterest(\n",
        "        name=\"obs2\",\n",
        "        points=[(8,8), (7,8), (7,7), (8,7)], \n",
        "        hole=(7.5,7.5)\n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"goal1\",\n",
        "        points=[(1,7), (1,8), (2,8), (2,7)], \n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"goal2\",\n",
        "        points=[(8,2), (7,2), (7,1), (8,1)], \n",
        "    ),\n",
        "    RegionOfInterest(\n",
        "        name=\"center\",\n",
        "        points=[(2,2), (3,6), (5,6), (6.5,6.5), (6,3)],\n",
        "        cost_per_unit=10.0 \n",
        "    ),\n",
        "]\n",
        "\n",
        "# define workspace bounds\n",
        "xmin = 0\n",
        "xmax = 10\n",
        "ymin = 0\n",
        "ymax = 10\n",
        "\n",
        "# create input file\n",
        "workspace_to_poly_file(xmin, xmax, ymin, ymax, regions=rois_w)\n",
        "# call triangle\n",
        "max_area = 1.5 #@param {type:\"slider\", min:0.1, max:5.0, step:0.1}\n",
        "call_triangle(max_area=max_area)\n",
        "# parse output\n",
        "vert_w, faces_w = parse_triangle()\n",
        "# vizualize the result\n",
        "viz_mesh(vert_w, faces_w, rois_w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5mnC-We-7Ir"
      },
      "source": [
        "### Exercise - Create a Weighted Transition System\n",
        "\n",
        "**Exercise:**\n",
        "* With these new regions, create a new triangulation.\n",
        "* Create a new Transition Sytem, but include costs on edges this time.\n",
        "* Make sure you correctly factor in the \"length\" of the transition between two faces into the cost. Big distances should somehow incur bigger costs. There are a lot of ways to model this, so choose your own and motivate the choice.\n",
        "\n",
        "**Hints:**\n",
        "* You can store data to edges: `ts.add_edge(s1, s2, cost=7.3)`\n",
        "* You can call data stored on edges: `ts.edges[s1, s2][\"cost\"]`\n",
        "* A starting point for distance computations could be the distance of face centroids.\n",
        "* Don't forget to also label your states, just like before!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSyMHzcT72V_"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "def wts_from_vert(vert, faces, rois):\n",
        "  wts = nx.DiGraph()\n",
        "  # PUT YOUR SOLUTION HERE\n",
        "  # fill the WTS\n",
        "  return wts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p4Oq35UQeMa"
      },
      "source": [
        "### Exercise - Product Automaton with Weights\n",
        "\n",
        "**Exercise:**\n",
        "* Extend your product automaton code to include edge weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xA1v-jrQxL0"
      },
      "outputs": [],
      "source": [
        "# PUT YOUR SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ex1l8cHBEqV"
      },
      "source": [
        "## Minimal Paths\n",
        "\n",
        "In order to find a \"good\" plan for the autonomous system, we can think of a path that minimizes cost. Since our paths will be infinite, the sum of all transition costs will always be infinite. Here, we compute prefixes and suffixes of minimal length and use the shortest suffix as the arbiter of lasso path choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sA-x-uRhsjT"
      },
      "outputs": [],
      "source": [
        "wts = wts_from_vert(vert_w, faces_w, rois_w)\n",
        "nba = ltl_to_nba(\"(G F goal1) && (G F goal2)\")\n",
        "prod_w = weighted_product_automaton(wts, nba)\n",
        "\n",
        "suffixes = min_suffixes(prod_w, weight=\"cost\")\n",
        "prefixes = min_prefixes(prod_w, weight=\"cost\")\n",
        "acc_state = min(suffixes, key=suffixes.get)\n",
        "prefix_path = [state[0] for state in prefixes[acc_state]]\n",
        "suffix_path = [state[0] for state in suffixes[acc_state]]\n",
        "\n",
        "viz_mesh(vert_w, faces_w, rois_w, highlight=prefix_path)\n",
        "viz_mesh(vert_w, faces_w, rois_w, highlight=suffix_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A-Level\n",
        "\n",
        "So far, this tutorial provided simple-to-understand and simple-to-read solutions to find lasso paths in the product automaton. However, the provided methods are not very efficient. While this does not matter much for the examples of this lab, efficient algorithms are necessary for bigger product automata.\n",
        "\n",
        "Nested Depth-First-Search [4] is a suitable and efficient algorithm to find accepting cycles in the product. Your task is to implement nested DFS and use it to find lasso paths in the **unweighted** product automaton from the E-level."
      ],
      "metadata": {
        "id": "_TZ3_VadoJ51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory - Basic Depth-First Search\n",
        "\n",
        "You might already know basic DFS, a classic graph traversal or search algorithm. It can be used to find a path from a starting state to any desired goal state.\n",
        "```\n",
        "proc dfs1(s)\n",
        "  add s to Stack\n",
        "  add s to States\n",
        "  for each transition (s,a,sâ) do\n",
        "    add {s,a,sâ} to Transitions\n",
        "    if sâ not in States then dfs1(sâ) fi\n",
        "  od\n",
        "  delete s from Stack\n",
        "end\n",
        "```"
      ],
      "metadata": {
        "id": "PVDi6JgQxQzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory - Nested Depth-First Search\n",
        "\n",
        "Nested Depth-First Search [4] is the same algorithm, but for lasso paths. After reaching a state in dfs1, it tries to find a cycle from that path. \n",
        "\n",
        "```\n",
        "proc dfs1(s)\n",
        "  add s to Stack1\n",
        "  add s to States1\n",
        "  if accepting(s) then States2:=empty; seed:=s; dfs2(s) fi\n",
        "  for each transition (s,a,sâ) do\n",
        "    add {s,a,sâ} to Transitions\n",
        "    if sâ not in States1 then dfs1(sâ) fi\n",
        "  od\n",
        "  delete s from Stack1\n",
        "end\n",
        "\n",
        "proc dfs2(s) /* the nested search */\n",
        "  add s to Stack2\n",
        "  add s to States2\n",
        "  for each transition (s,a,sâ) do\n",
        "    add {s,a,sâ} to Transitions2\n",
        "    if sâ == seed then report cycle\n",
        "    else if sâ not in States2 then dfs2(sâ) fi\n",
        "  od\n",
        "  delete s from Stack2\n",
        "end\n",
        "```\n",
        "Pseudocode taken from [[here]](https://www.win.tue.nl/~dragan/Thesis/PDF/Chapter7.pdf). The link also provides further explanation to the algorithm."
      ],
      "metadata": {
        "id": "lYd_9KoUxTYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise - Product Automaton\n",
        "\n",
        "**Exercise:**\n",
        "* Make yourself familiar with the Nested DFS algorithm. Use any sources you deem appropriate.\n",
        "* Document the sources you used to understand the algorithm.\n",
        "* Implement the Nested DFS search.\n",
        "* Compare the lasso paths your implementation with the ones found in the E-level. \n",
        "\n",
        "**Hints:**\n",
        "* [2] has good explanation for the nested DFS algorithm, but for the dual use-case of verification. They try to show that no lasso path exists, so a lasso path is called a counterexample."
      ],
      "metadata": {
        "id": "sjRfKm4Gwi8E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYbHGlg9jj67"
      },
      "source": [
        "# References\n",
        "\n",
        "* **[1]** Pnueli, Amir. \"The temporal logic of programs.\" 18th Annual Symposium on Foundations of Computer Science (sfcs 1977). ieee, 1977.\n",
        "* **[2]** Baier, Christel, and Joost-Pieter Katoen. Principles of model checking. MIT press, 2008.\n",
        "* **[3]** T. Babiak, M. KÅetÃ­nskÃ½, V. ÅehÃ¡k, and J. StrejÄek: LTL to BÃ¼chi Automata Translation: Fast and More Deterministic, in Proceedings of TACAS 2012, volume 7214 of LNCS, pages 95-109. Springer-Verlag, 2012.\n",
        "* **[4]** [[PDF]](https://spinroot.com/gerard/pdf/inprint/spin96.pdf) Holzmann, Gerard J., Doron A. Peled, and Mihalis Yannakakis. \"On nested depth first search.\" The Spin Verification System 32 (1996): 81-89."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Vsr2SzeLQDgS"
      ],
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}